{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(f\"/home/{os.getlogin()}/watttime-python-client-aer-algo\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pytz import UTC, timezone\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import concurrent.futures\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "from watttime import WattTimeForecast, WattTimeHistorical, RecalculatingWattTimeOptimizer\n",
    "\n",
    "import data.s3 as s3u\n",
    "import evaluation.eval_framework as efu\n",
    "from plotnine import *\n",
    "\n",
    "username = os.getenv(\"WATTTIME_USER\")\n",
    "password = os.getenv(\"WATTTIME_PASSWORD\")\n",
    "\n",
    "actual_data = WattTimeHistorical(username, password)\n",
    "hist_data = WattTimeForecast(username, password)\n",
    "\n",
    "s3 = s3u.s3_utils()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date_with_time(start, end):\n",
    "\n",
    "    time_between_dates = end - start\n",
    "    random_number_of_seconds = random.randint(0, int(time_between_dates.total_seconds()))\n",
    "    random_date = start + timedelta(seconds=random_number_of_seconds)\n",
    "    \n",
    "    random_hour = random.randint(0, 23)\n",
    "    random_minute = random.randint(0, 59)\n",
    "    \n",
    "    random_date_with_time = random_date.replace(hour=random_hour, minute=random_minute)\n",
    "    return pd.to_datetime(random_date_with_time, utc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_requery_sim(region, full_forecast, full_history, increments, start_time, end_time, usage_power_kw, time_needed, method = \"simple\"):\n",
    "\n",
    "    results = {}\n",
    "    all_relevant_forecasts = full_forecast.set_index(\"generated_at\")[start_time - timedelta(minutes = 5):end_time].reset_index()\n",
    "    all_relevant_forecasts = all_relevant_forecasts.set_index(\"generated_at\")[start_time - timedelta(minutes = 5):end_time]\n",
    "    baseline_forecast = all_relevant_forecasts.loc[all_relevant_forecasts.index.min()].reset_index()\n",
    "    schedules = []\n",
    "\n",
    "    ideal = efu.get_schedule_and_cost_api_requerying(region = \"SOCO\",\n",
    "                                        usage_power_kw = 2,\n",
    "                                        time_needed = time_needed,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=\"simple\",\n",
    "                                        moer_list = [full_history.set_index(\"point_time\")[start_time - timedelta(minutes = 5):end_time].reset_index()]).reset_index().rename({\"pred_moer\" : \"actual_moer\"}, axis = 1)\n",
    "\n",
    "    results[\"ideal_emissions\"] = round(ideal[\"emissions_co2e_lb\"].sum(), 2)\n",
    "    ideal[\"increment\"] = \"Ideal\"\n",
    "    ideal[\"pred_moer\"] = ideal[\"actual_moer\"]\n",
    "    ideal[\"actual_emissions\"] = ideal[\"actual_moer\"]*ideal[\"energy_usage_mwh\"]\n",
    "    schedules.append(ideal)\n",
    "\n",
    "\n",
    "    baseline = efu.get_schedule_and_cost_api_requerying(region = region,\n",
    "                                        usage_power_kw = usage_power_kw,\n",
    "                                        time_needed = time_needed,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=\"baseline\",\n",
    "                                        moer_list = [baseline_forecast]).reset_index()\n",
    "\n",
    "    baseline = baseline.merge(ideal[[\"point_time\", \"actual_moer\"]])\n",
    "\n",
    "    baseline[\"increment\"] = \"Baseline\"\n",
    "    baseline[\"actual_emissions\"] = baseline[\"actual_moer\"]*baseline[\"energy_usage_mwh\"]\n",
    "\n",
    "    schedules.append(baseline)\n",
    "\n",
    "    results[\"baseline_predicted_emissions\"] = round(baseline[\"emissions_co2e_lb\"].sum(), 2)\n",
    "    results[\"baseline_actual_emissions\"] = round((baseline[\"actual_moer\"]*baseline[\"energy_usage_mwh\"]).sum(), 2)\n",
    "\n",
    "    no_requery = efu.get_schedule_and_cost_api_requerying(region = region,\n",
    "                                        usage_power_kw = usage_power_kw,\n",
    "                                        time_needed = time_needed,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=method,\n",
    "                                        moer_list = [baseline_forecast]).reset_index()\n",
    "\n",
    "    no_requery = no_requery.merge(ideal[[\"point_time\", \"actual_moer\"]])\n",
    "    no_requery[\"increment\"] = \"No requery\"\n",
    "    no_requery[\"actual_emissions\"] = no_requery[\"actual_moer\"]*no_requery[\"energy_usage_mwh\"]\n",
    "    schedules.append(no_requery)\n",
    "\n",
    "    results[\"no_requery_predicted_emissions\"] = round(no_requery[\"emissions_co2e_lb\"].sum(), 2)\n",
    "    results[\"no_requery_actual_emissions\"] = round((no_requery[\"actual_moer\"]*no_requery[\"energy_usage_mwh\"]).sum(), 2)\n",
    "\n",
    "\n",
    "\n",
    "    for increment in increments:\n",
    "        inc_times = pd.date_range(all_relevant_forecasts.index.min(), all_relevant_forecasts.index.max(), freq=timedelta(minutes=increment))\n",
    "        moer_list = [all_relevant_forecasts.loc[timestamp].reset_index() for timestamp in inc_times]\n",
    "\n",
    "        print(len(moer_list))\n",
    "\n",
    "        schedule = efu.get_schedule_and_cost_api_requerying(region = region,\n",
    "                                        usage_power_kw = 2,\n",
    "                                        time_needed = 180,\n",
    "                                        start_time = start_time,\n",
    "                                        end_time = end_time, \n",
    "                                        optimization_method=method,\n",
    "                                        moer_list = moer_list).reset_index()\n",
    "        \n",
    "        \n",
    "        schedule = schedule.merge(ideal[[\"point_time\", \"actual_moer\"]])\n",
    "        schedule[\"actual_emissions\"] = schedule[\"actual_moer\"]*schedule[\"energy_usage_mwh\"]\n",
    "        schedule[\"increment\"] = f\"Requery {increment} minutes\"\n",
    "        schedules.append(schedule)\n",
    "\n",
    "\n",
    "        results[f\"schedule_predicted_emissions_requery_{increment}\"] = round(schedule[\"emissions_co2e_lb\"].sum(), 2)\n",
    "        results[f\"schedule_actual_emissions_requery_{increment}\"] = round((schedule[\"actual_moer\"]*schedule[\"energy_usage_mwh\"]).sum(), 2)\n",
    "\n",
    "    increment_order = [f\"Requery {increment} minutes\" for increment in increments]\n",
    "    order = [\"Ideal\", \"Baseline\", \"No requery\"] + increment_order[::-1]\n",
    "    full_schedules = pd.concat(schedules)\n",
    "    full_schedules[\"increment\"] = pd.Categorical(full_schedules[\"increment\"], order, ordered = True)\n",
    "\n",
    "    return full_schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic paramaters to get simple data. Will eventually be expanded to the synthetic users\n",
    "\n",
    "increments = [5, 15, 30, 60, 120, 180, 240, 360]\n",
    "start_time = random_date_with_time(datetime(2023, 1, 1), datetime(2023, 12, 31))\n",
    "end_time = start_time + timedelta(hours = 12)\n",
    "usage_power_kw = 2\n",
    "time_needed = 180\n",
    "\n",
    "\n",
    "regions = [\n",
    " 'CAISO_NORTH',\n",
    " 'SPP_TX',\n",
    " 'ERCOT_EASTTX',\n",
    " 'FPL',\n",
    " 'SOCO',\n",
    " 'PJM_CHICAGO',\n",
    " 'LDWP',\n",
    " 'PJM_DC',\n",
    " 'NYISO_NYC'\n",
    "]\n",
    "\n",
    "dates = [pd.to_datetime(random_date_with_time(datetime(2023, 1, 1), datetime(2023, 12, 31))) for i in range(0, 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for region in regions:\n",
    "    print(region)\n",
    "    full_forecast = s3.load_parquetdataframe(f\"complete_2023_forecast_history/{region}.parquet\").drop_duplicates()\n",
    "    full_forecast['point_time'] = pd.to_datetime(full_forecast['point_time'], utc=True)\n",
    "    full_history = s3.load_parquetdataframe(f\"complete_2023_actual_history/{region}.parquet\").drop_duplicates()\n",
    "\n",
    "    for date in tqdm(dates):\n",
    "        try:\n",
    "            with contextlib.redirect_stdout(io.StringIO()), warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)  \n",
    "                schedules = full_requery_sim(region, full_forecast, full_history, increments, date, date + timedelta(hours = 12), usage_power_kw, time_needed, method = \"simple\")\n",
    "            schedules[\"init_time\"] = date\n",
    "            schedules[\"region\"] = region\n",
    "            out.append(schedules)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "out_df = pd.concat(out)\n",
    "s3.store_parquetdataframe(out_df, f'historical_requery_sim_1000_simple_fit.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
